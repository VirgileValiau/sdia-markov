{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probability 2 (Data science Master, University of Lille) / CMF, (Centrale Lille, G3 SDIA)\n",
    "\n",
    "---\n",
    "\n",
    "## Lab 1 - Discrete time homogeneous Markov chains\n",
    "\n",
    "---\n",
    "\n",
    "## Guidelines (read carefully before starting)\n",
    "\n",
    "**Objectives**: numerically simulate basic Markov chains (discrete time and discrete state space).\n",
    "\n",
    "**Setup**: after retrieving the resources for the lab on moodle:\n",
    "- place the .zip archive in a local folder (Computer -> Documents/Python/);\n",
    "- unzip the archive .zip;\n",
    "- rename the folder with the convention lab1_Name1_Name2\n",
    "- duplicate the notebook file and rename it lab1_Name1_Name2.ipynb;\n",
    "- [**optional, possibly needed if working from Centrale's machines**]\n",
    "    - create a `lab1` conda environment from the provided `requirement.txt` file\n",
    "    ```bash\n",
    "    conda create --name=lab1 --file=requirement.txt\n",
    "    conda activate lab1\n",
    "    # do not forget to deactivate the environment if needed\n",
    "    # you can remove the environment once you are done\n",
    "    conda env remove --name=lab1\n",
    "    ```\n",
    "    - launch jupyter notebook (the python environment will be the one from the conda environment `lab1`)\n",
    "- at the end of the session, do not forget to transfer your work to your own network space if you are working on a machine from the school (do not leave your work on the C: drive).\n",
    "\n",
    "**Assessment** &#8594; grade /20 (possibly converted later on to a grade ranging from F to A (A+))\n",
    "\n",
    "This lab session will be evaluated, based on your answer to the exercises reported in a Jupyter notebook (e.g., this one) and any additional `.py` file produced. In particular:\n",
    "\n",
    "- make sure the notebook you produce is properly annotated: each exercise should be introduced by a short sentence summarizing its context. Concisely answer each question from the guideline. \n",
    "- **relate the numerical results to the theory covered during the lecture** whenever appropriate;\n",
    "- **codes without any explanations (in a text cell) will not be considered as a complete answer**, and will only be attributed a fraction opf the grade attributed to the question.\n",
    "- any code produced should be commented whenever appropriate;\n",
    "- include appropriate axis labels and a relevant title to each figure reported in the notebook;\n",
    "- **document any function you introduce (using docstrings)**, and comment your code whenever appropriate (see, *e.g.*, [PEP 8 style recommendations](https://www.python.org/dev/peps/pep-0008/)). \n",
    "     - use a reference docstring style, *e.g.*, the [google docstring style](https://sphinxcontrib-napoleon.readthedocs.io/en/latest/example_google.html).\n",
    "- **give a clear structure to your notebook**: longer theoretical explanations should be reported in markdown cells. Include LaTeX equations to improve the clarity of the document.\n",
    "\n",
    "**Additional evaluation criteria**:\n",
    "- Code clarity / conciseness / documentation\n",
    "- Comment quality / overall presentation    \n",
    "\n",
    "## <a name=\"content\">Contents</a>\n",
    "- [Exercise 1: Ehrenfest model](#ex1)\n",
    "- [Exercise 2: Simulation of a discrete time homogeneous Markov chain](#ex2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## <a name=\"ex1\">Exercise 1: Ehrenfest model</a> [(&#8593;)](#content) <!-- [$\\cdot$/10] -->\n",
    " Consider a system of $K = 30$ particles (labeled from 1 to $K$) evolving in a closed box. The box is divided into two compartments in contact with each other, respectively identified by an index, $0$ and $1$. A hole at the interface between the two compartments allows the particles to move from one compartment to the other.\n",
    "\n",
    " Particle motion is modeled as follows: at each discrete time intant $n$, one particle is chosen uniformly at random and moved from its current compartment to the other. Let $X(n)$ denote the number of particles in compartment $0$ at time $n$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1\\. <!--[$\\cdot$/0.5]--> Briefly justify that $\\bigl(X(n) \\bigr)_{n \\in \\mathbb{N}}$ is a Markov chain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\bigl(X(n) \\bigr)_{n \\in \\mathbb{N}}$ is a sequence of random variables with values in S={0,1,2,...,N}.\n",
    "\n",
    "The probability of the next state just depends on the actual state, and does not care about the previous state. It is a memory-less process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2\\. <!--[$\\cdot$/1.5]--> Is the chain irreducible? (Positive) recurrent? Aperiodic or periodic? Prove each statement from your answer (recall the main steps covered during the exercise session)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From each state we can reach any other state with a positive probability, so there is only one communication class, so the chain is irreducible.\n",
    "\n",
    "As the chain is irreducible and the number of states values are finite, the chain is recurrent.\n",
    "\n",
    "When we are in an even state, (X(n) = 2k, k in $\\mathbb{N}$), the next state will automatically be an odd state, which is true on both ways. So the chain is 2-periodic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3\\. <!--[$\\cdot$/0.5]--> Recall the structure of the transition matrix, and encode it in Python (without any for loop).\n",
    "\n",
    " > Hint: use the function `numpy.diag`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have $p_{i,i+1} = \\frac{i+1}{K}$ \n",
    "\n",
    "$p_{i,i-1} = \\frac{K - (i-1)}{K}$\n",
    "\n",
    "And $p_{i,j} = 0$ for any other case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 30\n",
    "D1 = np.arange(1,K+1)/K\n",
    "D2 = np.flip(D1)\n",
    "P = np.diag(D2,k=1) + np.diag(D1,k=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\\. <!--[$\\cdot$/0.5]-->Numerically verify that the binomial distribution $\\mathcal{B} (K, 1/2)$ is invariant for the chain. This invariant distribution will be denoted by $\\pi$ in the rest of the exercise.\n",
    "\n",
    " > Hint: you can use `scipy.stats.binom`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pi = stats.binom(K,0.5).pmf(np.arange(0,K+1))\n",
    "print(np.round(Pi@P-Pi,15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see here that the difference of Pi and Pi.P is 0, if we forget about the machine precision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5\\. <!--[$\\cdot$/2]--> Implement a Python function `ehrenfest` to simulate a trajectory of the chain for a system of $K$ particles, for initial distribution $\\mu$ (for instance a Dirac centered in $0$, meaning that the compartment $0$ is empty at $n = 0$). The maximum number of time steps will be controlled by an input parameter $n_{\\max}$.\n",
    "\n",
    "For an efficient implementation, **do not use vector-matrix product with the transition matrix implemented in 3**: rely on the description of the system instead.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ehrenfest(K,nmax = 10):\n",
    "    A = 0\n",
    "    B = K\n",
    "    res=np.zeros(nmax+1)\n",
    "    n=0\n",
    "    while n<nmax:\n",
    "        p = np.random.rand()\n",
    "        if p <= A/K:\n",
    "            A-=1\n",
    "            B+=1\n",
    "        else:\n",
    "            B-=1\n",
    "            A+=1\n",
    "        n+=1\n",
    "        res[n] = A\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6\\. Simulate a trajectory of the chain starting in state $0$ for $n_{\\max} = 5000$. Display the result in function of the time index $n$. Briefly describe the curve you obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ehrenfest(30,nmax = 5000)\n",
    "print(np.mean(X))\n",
    "plt.plot(range(len(X)),X)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The curve seems to turn around 15 which correspond to K/2. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7\\. Compare the empirical histogram of the trajectory obtained in 5. to the theoretical limit distribution $\\pi$. What do you observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(X,bins = range(0,K+1),density=True)\n",
    "plt.plot(range(len(Pi)),Pi)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8\\. a) Modify the function defined in 5. so that it returns the return time to state 0, defined as $T_{0,0} = \\inf \\bigl\\{ n > 0, X(n) = 0 \\mid X(0) = 0 \\bigr\\}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ehrenfest_time(K,nmax = 5000):\n",
    "    A = 0\n",
    "    B = K\n",
    "    n=0\n",
    "    reached= False\n",
    "    while (not reached) and (n<nmax):\n",
    "        p = np.random.rand()\n",
    "        if p <= A/K:\n",
    "            A-=1\n",
    "            B+=1\n",
    "        else:\n",
    "            B-=1\n",
    "            A+=1\n",
    "        n+=1\n",
    "        if A==0:\n",
    "            reached = True\n",
    "    return n\n",
    "\n",
    "print(ehrenfest_time(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8\\. b) [**Optional**] Run several chains (about 5, ideally in parallel) for $K = 10$, $n_{\\max} = 5000$, and compare the empirical average of $T_{0,0}$ to $\\pi(0)$. What do you observe?\n",
    " > Hint: a good tutorial showing how to run functions in parallel in Python is available [here](https://www.machinelearningplus.com/python/parallel-processing-python/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N=1000\n",
    "K=10\n",
    "L=np.zeros(N)\n",
    "for i in range(N):\n",
    "    L[i] = ehrenfest_time(K,500000)\n",
    "\n",
    "Pi = stats.binom(K,0.5).pmf(np.arange(0,K+1))\n",
    "\n",
    "print(1/Pi[0],np.mean(L))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that the empirical mean of $T_{0,0}$ is not far from the inverse of $\\pi(0)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8\\. c) Comment on the possibility of numerically observing the chain returning to its initial state as $K$ increases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## <a name=\"ex2\">Exercise 2: Simulation of a discrete time homogeneous Markov chain</a> [(&#8593;)](#content)\n",
    " Let $\\bigl( X(n) \\bigr)_{n \\in \\mathbb{N}}$ be a discrete time homogeneous Markov chain defined by the following initial distribution $\\mu$ and transition matrix $P$\n",
    "\n",
    "$$\n",
    "     \\mu = [0, 1, 0, 0, 0, 0], \n",
    "     %\n",
    "     \\quad\n",
    "     %\n",
    "     P = \\begin{pmatrix}\n",
    "       1/2   & 1/2 &0  &0   &0   &0   \\\\\n",
    "\t \t1/4 &0   &0  &1/4 &1/4 &1/4   \\\\\n",
    "       1/2   &0   &0  &0   &0   &1/2 \\\\\n",
    "       0   &1/2 &0  &0   &1/2 &0   \\\\\n",
    "       0   &1/3 &0  &1/3 &0   &1/3 \\\\\n",
    "       0   &1/3 &1/3  & 0 &1/3   &0\n",
    "     \\end{pmatrix}.\n",
    " $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. What can you say about the Markov chain $X$? (irreducibility, positive recurrence, periodicity, ...). Justify each of your claim, citing the relevant results from the lecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. Write a function `simulate_dthmc` simulating the trajectory of the Markov chain $\\bigl( X(n) \\bigr)_{n \\in \\mathbb{N}}$ for $n_{\\max}$ time steps. The signature of the function should include the following elements:\n",
    "   - list of inputs: transition matrix $P$, initial distribution $\\mu$, number of time steps $n_{\\max}$;\n",
    "   - output: array of lenght $n_{\\max}$ representing the trajectory.\n",
    "   \n",
    "**To this end, do not use matrix vector products, which would lead to an extremely inefficient algorithm in this case.**\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_dthmc(P,mu,nmax):\n",
    "    N=len(mu)\n",
    "    res = np.zeros(nmax)\n",
    "    mu = np.nonzero(mu)[0][0]\n",
    "    res[0] = mu\n",
    "    for i in range(nmax-1):\n",
    "        mu = np.random.choice(range(N),p=P[mu])\n",
    "        res[i+1] = mu \n",
    "    return res  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. Simulate a trajectory of the chain for $n_{\\max} = 2000$ starting from $X(0) = 1$. Plot the histogram of the states visited by the chain.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "P =np.array(\n",
    "    [[1/2, 1/2, 0, 0, 0, 0 ],\n",
    "    [1/4, 0, 0, 1/4, 1/4, 1/4],\n",
    "    [1/2, 0, 0, 0, 0, 1/2],\n",
    "    [0, 1/2, 0, 0, 1/2, 0],\n",
    "    [0,1/3, 0, 1/3, 0, 1/3],\n",
    "    [0 , 1/3, 1/3, 0 ,1/3, 0]])\n",
    "\n",
    "mu = np.array([1,0,0,0,0,0])\n",
    "\n",
    "traj = simulate_dthmc(P,mu,2000)\n",
    "print(traj)\n",
    "\n",
    "plt.hist(traj,bins = len(mu),range=(0,6),density=True,color = 'white',edgecolor='red',rwidth=0.8,align='left',label='Empirical histogram of the trajectory')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\\. Determine numerically an invariant distribution $\\boldsymbol{\\pi}$ of the chain (*e.g.*, based on an eigendecomposition [numpy.linalg.eig](https://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.eig.html)). Is it unique? Compare it to the histogram obtained in 2 (superimpose graphs). What can you conclude?\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,eig_vecs = np.linalg.eig(P.T)\n",
    "pi=[]\n",
    "for vec in eig_vecs.T:\n",
    "    if np.linalg.norm((vec.imag)) == 0:\n",
    "        pi.append(vec.real)\n",
    "\n",
    "pi = pi[0]/np.sum(pi[0])\n",
    "\n",
    "plt.hist(traj,range=(0,6),bins = len(mu),density=True,color = 'white',edgecolor='red',rwidth=0.25,label='Empirical histogram of the trajectory')\n",
    "plt.bar(range(len(pi)),height = pi,width=0.25,color =\"white\",edgecolor=\"blue\",align='edge',label='Invariant distribution')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5\\. a) Compute $\\mu_n \\triangleq \\mu P^n$, the probability distribution of $X(n)$. What is the limit of $\\mu_n$ as $n$ goes to $+\\infty$? Illustrate the result numerically.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = np.array([1,0,0,0,0,0])\n",
    "\n",
    "N=200\n",
    "for i in range(N):\n",
    "    mu = mu@P\n",
    "\n",
    "print(np.linalg.norm(mu-pi))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5\\. b) Display on the same graph the curves $n \\mapsto \\mu_n(i)$ for $i = 1, \\dotsc , 6$, and compare with $\\pi$. Display on another graph the function $n \\mapsto \\Vert \\mu_n - \\pi \\Vert_1$, where $\\Vert \\cdot \\Vert_1$ is the $\\ell_1$ norm. What does each of these curves illustrate?\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = np.array([1,0,0,0,0,0])\n",
    "\n",
    "N=20\n",
    "dist = np.zeros(N)\n",
    "Mu = np.zeros((N,len(mu)))\n",
    "for i in range(N):\n",
    "    mu = mu@P\n",
    "    dist[i] = np.linalg.norm(mu-pi)\n",
    "    Mu[i]= mu\n",
    "\n",
    "for k in range(len(mu)):\n",
    "    plt.plot(range(N),Mu[:,k])\n",
    "plt.show()    \n",
    "    \n",
    "plt.plot(range(N),dist,label='Distance euclidienne entre mu^n et pi')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6\\. For each state $i \\in \\{1, \\dotsc, 5 \\}$, simulate 100 trajectories starting from the state $i$ until the return time to $i$. For each state, compute the (empirical) average return time. Compare with its theoretical value.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
